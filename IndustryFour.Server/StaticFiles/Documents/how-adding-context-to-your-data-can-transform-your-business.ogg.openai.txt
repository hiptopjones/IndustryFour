Additive data context, take zero. All right, so I actually did this post on LinkedIn, so there's an accompanying LinkedIn post that goes with this whiteboard video. But there's been a lot of conversations about data context lately. When we talk about data ops or data operations, we're really talking about how do we take a raw data event and turn it into something meaningful for a business. And generally, we don't talk about the technical elements of data ops in a public forum, so like on YouTube or in LinkedIn. Generally, we're doing that in a training session when we're training our mastermind or mentorship students. Why? Because the vast majority of the audience that we have in our public forums are non-technical, 70%, give or take. There's a lot of business development people, et cetera, et cetera. But in this video, what I'm going to do here is I'm going to sketch out what additive data context actually is using the example we have on LinkedIn in my LinkedIn post, which will be linked in the comment down below. But anyway, we created this infographic to demonstrate additive data context in data operations. And what's important to note is that for the use case that we're going to talk about here, we're going to talk about taking the value off of a sensor that is counting parts as it comes off a machine. And we're going to talk about all the places where context gets added to that data point before it achieves the total amount of value that it provides to your business. So we created this infographic, though, to kind of explain the various layers of additive context that data gets. So number one, you have the raw data event. So the raw data event is the digital event, often from a sensor. But sometimes it can be coming off of a function block in a PLC, or off of I-O in a PLC, or an event in an edge device. So it could be an edge device that is capturing a raw event. And that's a value with a time stamp, and it means something. It's measuring something. So that's the raw data event. That data event, by the way, if it's just the rising edge of, let's say it's a counter. So we're just detecting, and at the rising edge, all we're doing is we're measuring a part. So this means that we have additional, a new part. That raw data event, this event itself, this is the event, it means nothing. It is of no value to the business without any additional context. Like, one count means absolutely nothing to me. The rising edge of that event means absolutely nothing. I need additional context. Like, what is it counting? How many has it counted, the aggregation, altogether? So the raw event off the sensor is just the beginning. Without context, it can't provide any value to the business. So what we try to do is we try to create architecture specifically with the unified namespace so we can add that context. Number two is the initial context from that raw sensor. So this is gonna be the earliest interpretation of the raw data, where rudimentary identifiers such as the timestamp, the source, and the type are applied. For example, in a user-defined data type or AOI. So what we do is we take the raw event, which looks something like that. Okay, if I put an oscilloscope, it's gonna look basically something like that. And I'm gonna turn it with the initial context, I'm gonna turn it into something else. So I may have an AOI, which is called sensor, okay? And in that initial context, I may have something like the timestamp, the value, the sensor ID, okay? And the type, which we'll say it's a counter. So now what I've done is in the initial context, I have applied four parameters, two of which are from the raw event. So this is time and this is value, okay? One and zero, okay? Timestamp and value come from the raw sensor, but the sensor ID and the counter, the type, they're coming from the data type, which is in our initial context, okay? So that's step two in data context. And in fact, what we did as part of the original post on LinkedIn, I showed you what it would look like at the raw event, if I was using a JSON, for example. If I was using a JSON, and then this is the initial context, okay? So the raw event is the sensor, and in this case, it's sensor ID and value, so it should be timestamp and value. This is if we were looking at it in a JSON, and in the PLC, we have the type counter, timestamp, model number, manufacturer, raw low, raw high, engineering low, engineering high. All that comes from the data type, okay? So that second step is applying initial context. The next step is the operational context, okay? So this is the process where raw data is processed and integrated into various systems, each adding its unique layer of context. So for example, I may have a SCADA system over here, which is going to now consume this as an item. Let's say I'm consuming it as an OPC item into my SCADA system, okay? And so now what I've got is my sensor plus my attributes underneath it. And now what I might do is I might apply to my value, I might apply new context. And that context might be my alarm definitions. So high, low, and active, okay? So I may apply in my SCADA system just to this additional value, additional context, where now what I've done is I've created alarms on that value, and they now live in this part of our system. Now, generally, if we look at linear integration, what we talk about, which is the bane of Industry 4.0, this raw data event lives one place, this initial context lives another, this initial context, this ops context lives in another place, okay? What we do is we use the unified namespace so that all of these are interoperating through one common place. So I may also have raw sensor here. This is my unified namespace where my raw sensor publishes to here, my PLC publishes to there, my SCADA system publishes to there, which then adds in alarms, right? And then what we do is we move to the next layer of additive context, which is our data enrichment. So in this case, data enrichment, which is generally in our MES layer, so this is the augmentation of raw data with additional information from other sources, further enhancing its values and utility, specifically MES, what we would do here is we would subscribe to that, consume it, we would process it, and now what we do is at a level above sensor, we would publish back OEE calculation, okay? That's a good example, all right? Then from there, the next layer is business context. So this is the raw sensor, this is generally in the PLC, this is generally in the SCADA system, this is generally in the MES system, this is generally coming from the ERP. Business context is how the enriched data fits into the larger operational picture, including its relevance to production, maintenance, and process control, for example, ERP, okay? And I'm gonna actually stop there, above this is cross-functional data, is cross-org correlation, analytics, and then artificial intelligence, but you get the point here. So how does this all work together, okay? This is a very, very important point when we're talking about architecture, okay? And you'll notice when we build our unified namespaces, enterprise, site, area, line, and then cell, in here we'll have our raw, we'll have our PLC context, we won't call it PLC, we'll have our MES context, we'll have our ERP context. And all of it works together in a semantic hierarchy to create the context for the business. That is additive context. Every architecture, every business context, every architecture that we design in industry 4.0, that actually scales for all these organizations that are looking to digitally transform their business, we are applying the concept of additive context. Now, we don't talk about it publicly very often, because if I'm being honest with you, the concept goes over the vast majority of people's heads, but it is absolutely critical to a successful digital transformation journey, why? Because I can easily using, we use edge-driven report by exception, lightweight technology. Generally, this would be like an MQTT topical namespace. There's a big reason why OPC UA doesn't work here unless you're using PubSub part 14. But the big reason is because as we get smarter in our organization, we may wanna apply additional context. So new, new, I may wanna add context here, new, and I can with this architecture, okay? This is a very, very important point. The question that everyone needs to ask themselves when they're looking at, we talk about the three prerequisites you must have before you start your digital transformation journey, before you ever break ground on your proof of concept, strategy, architecture, minimum technical requirements. Okay, the strategy is why you wanna be a digital company. Okay, what is the reason we wanna be digital? How are we gonna make data our primary commodity and how are we gonna make products to get better after clients buy them? Number two, our architecture is how are we gonna put it all together? What's it gonna look like? This is an architecture with many other elements around it. And minimum technical requirements is the technology that all the nodes in the ecosystem, all the publishers that are gonna put data into your digital ecosystem must meet at a minimum. Otherwise, you have to put a gateway between that data generator and consumer and your infrastructure so that it will convert it into the technology that you're using, all right? All right, hopefully that clarifies data context. If you like this video or you think someone might benefit from it, share it, like, subscribe, comment down below and I'll see you in the next one.